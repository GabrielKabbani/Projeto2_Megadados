{
  "metadata": {
    "name": "Projeto",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd \u003d sc.textFile(\u0027s3://megadados-alunos/dados/all_reviews_clean_tsv/\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ncolumn_names \u003d [\"marketplace\",\"customer_id\", \"review_id\",\"product_id\",\"product_parent\",\"product_title\",\"product_category\",\"star_rating\",\"helpful_votes\",\"total_votes\",\"vine\",\"verified_purchase\",\"review_headline\",\"review_body\",\"review_date\"]\n\ndf \u003d spark.read.option(\"header\", \"false\").option(\"delimiter\", \"\\t\").csv(\"s3://megadados-alunos/dados/all_reviews_clean_tsv/\")\ndf \u003d df \\\n    .withColumnRenamed(\"_c0\", column_names[0])\\\n    .withColumnRenamed(\"_c1\", column_names[1])\\\n    .withColumnRenamed(\"_c2\", column_names[2])\\\n    .withColumnRenamed(\"_c3\", column_names[3])\\\n    .withColumnRenamed(\"_c4\", column_names[4])\\\n    .withColumnRenamed(\"_c5\", column_names[5])\\\n    .withColumnRenamed(\"_c6\", column_names[6])\\\n    .withColumnRenamed(\"_c7\", column_names[7])\\\n    .withColumnRenamed(\"_c8\", column_names[8])\\\n    .withColumnRenamed(\"_c9\", column_names[9])\\\n    .withColumnRenamed(\"_c10\", column_names[10])\\\n    .withColumnRenamed(\"_c11\", column_names[11])\\\n    .withColumnRenamed(\"_c12\", column_names[12])\\\n    .withColumnRenamed(\"_c13\", column_names[13])\\\n    .withColumnRenamed(\"_c14\", column_names[14])"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Tarefa 1:\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ncount \u003d rdd.count()\nprint(\"Tarefa 1: Quantos reviews existem? ---\u003e {0} reviews\".format(count))"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nclientes_existentes \u003d df[[\"customer_id\"]].distinct().count()\nprint(\"Tarefa 1: Quantos clientes existem? ---\u003e {0} clientes\".format(clientes_existentes))"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nprodutos \u003d df[[\"product_id\"]].distinct().count()\nprint(\"Tarefa 1: Quantos produtos existem? ---\u003e {0} produtos\".format(produtos))"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrating \u003d df[\"star_rating\"]\nprint(\"Tarefa 1: Quantos reviews existem para cada star rating?:\")\ndf.where((rating \u003d\u003d \u00271\u0027) | (rating \u003d\u003d \u00272\u0027) | (rating \u003d\u003d \u00273\u0027) | (rating \u003d\u003d \u00274\u0027) | (rating \u003d\u003d \u00275\u0027)).groupBy(\"star_rating\").count().show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Tarefa 2:\n######## Além do conteúdo das aulas, utilizamos a seguinte referência para aprofundar os quesitos relevantes na caracterização de bots: https://finance.yahoo.com/news/rise-fake-amazon-reviews-spot-175430368.html, e vimos que fazer várias reviews no mesmo dia é algo característico de bots."
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nrepeat_date_reviews \u003d df.groupBy(\"customer_id\", \"product_title\", \"product_category\", \"star_rating\", \"review_date\").count()\nrdr_ordered\u003d repeat_date_reviews.orderBy([\"count\"], ascending\u003dFalse)\nrdr_filtered\u003d rdr_ordered.filter(((rdr_ordered[\"count\"]) \u003e\u003d 2) )\nrdr_filtered_ordered\u003d rdr_filtered.orderBy([\"count\"], ascending\u003dFalse)"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ncount\u003drdr_filtered_ordered[[\"customer_id\"]].distinct().count()\nprint(\"Número de bots: {}\".format(count))\nprint(\"Porcentagem de bots: {}%\".format((count/clientes_existentes)*100))"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrating \u003d rdr_filtered_ordered[\"star_rating\"]\nrdr_filtered_ordered.where((rating \u003d\u003d \u00271\u0027) | (rating \u003d\u003d \u00272\u0027) | (rating \u003d\u003d \u00273\u0027) | (rating \u003d\u003d \u00274\u0027) | (rating \u003d\u003d \u00275\u0027)).groupBy(\"star_rating\").count().show()"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nrdr_filtered_ordered.groupBy(\"product_category\").count().orderBy([\"count\"], ascending\u003dFalse).show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Tarefa 3:\n######## Baseado no exemplo disponível em: https://ai.plainenglish.io/build-naive-bayes-spam-classifier-on-pyspark-58aa3352e244"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.feature import CountVectorizer\nfrom pyspark.ml.feature import Tokenizer, RegexTokenizer\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import NaiveBayes\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.functions import when\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nnaive_bayes \u003d df.select(\"star_rating\",\"review_body\")\ndf_class \u003d  naive_bayes.withColumn(\"nb\", when(naive_bayes[\"star_rating\"] \u003d\u003d \"1\", \"negativo\").when(naive_bayes[\"star_rating\"] \u003d\u003d \"2\", \"negativo\").when(naive_bayes[\"star_rating\"] \u003d\u003d \"3\", \"negativo\").when(naive_bayes[\"star_rating\"] \u003d\u003d \"4\", \"neutro\").when(naive_bayes[\"star_rating\"] \u003d\u003d \"5\", \"positivo\"))\ndf_class.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nnaive_bayes_final \u003d df_class.select(\"review_body\",\"nb\")\nnaive_bayes_final\u003dnaive_bayes_final.na.drop()\nnaive_bayes_final.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#auxilio do exemplo\n\nstages \u003d []\n\nregexTokenizer \u003d RegexTokenizer(inputCol\u003d\"review_body\", outputCol\u003d\"tokens\", pattern\u003d\"\\\\W+\")\nstages +\u003d [regexTokenizer]\n\n\ncv \u003d CountVectorizer(inputCol\u003d\"tokens\", outputCol\u003d\"token_features\", minDF\u003d2.0)#, vocabSize\u003d3, minDF\u003d2.0\nstages +\u003d [cv]\n\n\nindexer \u003d StringIndexer(inputCol\u003d\"nb\", outputCol\u003d\"label\")\nstages +\u003d [indexer]\n\n\nvecAssembler \u003d VectorAssembler(inputCols\u003d[\u0027token_features\u0027], outputCol\u003d\"features\")\nstages +\u003d [vecAssembler]\n\n[print(\u0027\\n\u0027, stage) for stage in stages]\n"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\npipeline \u003d Pipeline(stages\u003dstages)\ndata \u003d pipeline.fit(naive_bayes_final).transform(naive_bayes_final)"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ntrain, test \u003d data.randomSplit([0.7, 0.3], 2018)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# Initialise the model\nnb \u003d NaiveBayes(smoothing\u003d1.0, modelType\u003d\"multinomial\")\n# Fit the model\nmodel \u003d nb.fit(train)\n# Make predictions on test data\npredictions \u003d model.transform(test)\npredictions.select(\"label\", \"prediction\", \"probability\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nevaluator \u003d BinaryClassificationEvaluator(rawPredictionCol\u003d\"prediction\")\naccuracy \u003d evaluator.evaluate(predictions)\nprint (\"Model Accuracy: \", accuracy)"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n\nparamGrid \u003d ParamGridBuilder().addGrid(nb.smoothing, [0.0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.5, 2.0]).build()\ncvEvaluator \u003d BinaryClassificationEvaluator(rawPredictionCol\u003d\"prediction\")\n\n\ncv \u003d CrossValidator(estimator\u003dnb, estimatorParamMaps\u003dparamGrid, evaluator\u003dcvEvaluator)\ncvModel \u003d cv.fit(train)\n\n\ncvPredictions \u003d cvModel.transform(test)\n\n\nevaluator.evaluate(cvPredictions)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}